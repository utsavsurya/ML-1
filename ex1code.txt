import numpy as np 
import pandas as pd 
import seaborn as sns
import plotly 
import chart_studio
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
%matplotlib inline

import chart_studio.plotly as py
from plotly import __version__
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot

import cufflinks as cf

# For Notebooks
init_notebook_mode(connected=True)

# For offline use
cf.go_offline()


dat = pd.read_excel('ex1data1.xlsx',header=None)
dat.columns=['Population','Profit']
df = pd.DataFrame(data=dat)

arr = np.array(df)
X = arr[:,0] 
Y = arr[:,1]
Y.reshape(97,1)
print(X.shape,Y.shape)

plt.show()
plt.xlabel("Population of City in 10,000s")
plt.ylabel("Profit in $10,000s")
plt.scatter(X,Y,marker='x',c='r',)

m = len(X) # number of training examples
X = np.concatenate((np.ones((m,1)),arr[:,0].reshape(m,1)),axis=1) # Add a column of ones to x
theta = np.zeros((2, 1)) # initialize fitting parameters
iterations = 1500
alpha = 0.01
print(X.shape,theta.shape)

def ComputeCost(X,y,theta):
    m = len(y)
    #h = np.matmul(X,theta)
    h = X.dot(theta)
    squaredError = np.square(h - y.reshape(m,1))
    j = (1/(2*m)) * np.sum(squaredError)
    return j
ComputeCost(X, Y, theta) 
ComputeCost(X,Y,np.array([[-1],[2]]))

def GdientDescent(X, y, theta, alpha, num_iters):
    m = len(y); # number of training examples
    y = y.reshape(m,1)
    J_history = np.zeros(num_iters).reshape(num_iters,1)
    T_history = np.zeros((num_iters,2))
    #print(X.shape,theta.shape)

    for i in range(num_iters):
        h = np.matmul(X,theta)
        theta = theta - (alpha * ((1 / m) * (X.T.dot((h - y)))))
        #theta = (alpha * ((1 / m) * (X * (h - y))))
        T_history[i,:] = theta.T
        J_history[i] = ComputeCost(X,y,theta)
        
    return theta,J_history,T_history

theta,J_history,T_history = GdientDescent(X, Y, theta, alpha, iterations)

print('Theta computed from gradient descent: \n Theta0 = {0} \n Theta1 = {1}'.format(theta[0][0],theta[1][0]))

theta

predict1 = np.array([1, 3.5]).dot(theta);
print('For population = 35,000, we predict a profit of', predict1*10000);

predict2 = np.array([1, 7]).dot(theta);
print('For population = 70,000, we predict a profit of', predict2*10000);

plt.show()
plt.xlabel("Iterations")
plt.ylabel("J(theta)")
plt.plot(np.arange(iterations),J_history)

t1 = T_history[:,0]
t2 = T_history[:,1]
J_vals = np.zeros((len(t1),len(t2)))
for i in range(len(t1)):
    for j in range(len(t2)):
        t = np.array([t1[i],t2[j]])
        J_vals[i][j] = ComputeCost(X,Y,t)

J_val

df = pd.DataFrame(J_vals)
df.iplot(kind='surface',colorscale='rdylbu')